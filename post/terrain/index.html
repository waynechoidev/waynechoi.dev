<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/2e2a7597edf4d608.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/602feae4669a507e.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-c25d000de3a6a081.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-33f88dcb8cab817d.js" async="" crossorigin=""></script><script src="/_next/static/chunks/472-c5427e31248623a0.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-998ad79e34130139.js" async="" crossorigin=""></script><script src="/_next/static/chunks/326-6784f49434136418.js" async=""></script><script src="/_next/static/chunks/app/layout-a7d9660fe841e21f.js" async=""></script><script src="/_next/static/chunks/691-d72542b099e0bc41.js" async=""></script><script src="/_next/static/chunks/app/post/%5Bslug%5D/page-e90f3bafd107b713.js" async=""></script><title>WayneChoi.Dev</title><meta name="description" content="Wayne Choi blog"/><link rel="icon" href="/favicon.ico"/><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body class="mx-auto my-0"><nav class="max-w-default mx-auto px-5 py-3"><div class="flex justify-end"><a href="/about/"><span class="hover:font-bold pl-3 text-lg font-normal">About</span></a><a href="/posts/"><span class="hover:font-bold pl-3 text-lg font-normal">Posts</span></a></div></nav><header><div class="h-32 relative" id="sky"><canvas class="w-full h-full"></canvas><div class="absolute top-0 inset-x-auto w-full "><div class="w-full max-w-default mx-auto"><h1 class="text-4xl font-semibold p-5 pt-0"><a class="text-blue-800" href="/">WayneChoi.dev</a></h1></div></div></div></header><div class="max-w-default mx-auto p-5"><div><a class="text-gray-600 text-md pl-1 hover:font-bold" href="/posts/graphics/">GRAPHICS</a><h1>Terrain</h1><p class="text-gray-400 text-sm m-0 mt-1">Sep 11, 2024</p><div class="mt-1"><div class="whitespace-nowrap overflow-x-auto pb-3"><a class="mr-2 text-gray-500 hover:font-bold" href="/tag/simulation/">#simulation</a><a class="mr-2 text-gray-500 hover:font-bold" href="/tag/webgpu/">#webgpu</a><a class="mr-2 text-gray-500 hover:font-bold" href="/tag/noise/">#noise</a></div></div><div class="mt-8"><div class="flex flex-col justify-center"></div></div><div><div></div></div></div></div><footer class="h-40 flex justify-center items-end"><p class="text-gray-500 text-sm">(C) 2021. Wayne Choi. All rights reserved.</p></footer><script src="/_next/static/chunks/webpack-c25d000de3a6a081.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/2e2a7597edf4d608.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/css/602feae4669a507e.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"4:I[3728,[],\"\"]\n6:I[9928,[],\"\"]\n7:I[9194,[\"326\",\"static/chunks/326-6784f49434136418.js\",\"185\",\"static/chunks/app/layout-a7d9660fe841e21f.js\"],\"\"]\n8:I[5629,[\"326\",\"static/chunks/326-6784f49434136418.js\",\"185\",\"static/chunks/app/layout-a7d9660fe841e21f.js\"],\"\"]\n9:I[6954,[],\"\"]\na:I[7264,[],\"\"]\nc:I[8326,[\"326\",\"static/chunks/326-6784f49434136418.js\",\"691\",\"static/chunks/691-d72542b099e0bc41.js\",\"605\",\"static/chunks/app/post/%5Bslug%5D/page-e90f3bafd107b713.js\"],\"\"]\nd:I[7708,[\"326\",\"static/chunks/326-6784f494341"])</script><script>self.__next_f.push([1,"36418.js\",\"691\",\"static/chunks/691-d72542b099e0bc41.js\",\"605\",\"static/chunks/app/post/%5Bslug%5D/page-e90f3bafd107b713.js\"],\"\"]\nf:I[5631,[\"326\",\"static/chunks/326-6784f49434136418.js\",\"691\",\"static/chunks/691-d72542b099e0bc41.js\",\"605\",\"static/chunks/app/post/%5Bslug%5D/page-e90f3bafd107b713.js\"],\"\"]\ne:T214a,"])</script><script>self.__next_f.push([1,"\n\u003cimg src=\"/img/terrain.jpg\" class=\"post-pic\"/\u003e\n\n[Sample](https://waynechoidev.github.io/terrain/) / [Repository](https://github.com/waynechoidev/terrain/)\n\nI implemented terrain generation based on Perlin noise using WebGPU. Additionally, I added diverse effects such as shadows to enhance the visual richness, and I'll briefly explain the process.\n\n## 1. Perlin noise\n\n```js\nfn main(@builtin(global_invocation_id) id: vec3u) {\n    let x = id.x;\n    let y = id.y;\n    let idx = getIdx(id.xy);\n\n    let uv = vec2\u003cf32\u003e(f32(x) / f32(TEX_SIZE) + uni.progress, f32(y) / f32(TEX_SIZE));\n\n    var height = noise_sum(uv, mat2x2\u003cf32\u003e(231.1, 283.7, 143.8, 113.3), 14232.34234);\n    height = (height + 1.0) * 0.5;\n\n    var color = noise_sum(uv, mat2x2\u003cf32\u003e(423.5, 342.3, 153.7, 342.5), 18473.58352);\n    color = (color + 1.0) * 0.5;\n\n    textureStore(noise_texture, vec2\u003ci32\u003e(i32(x), i32(y)), vec4\u003cf32\u003e(height, color, 0, 255));\n}\n\nfn hash22(p: vec2\u003cf32\u003e, mat: mat2x2\u003cf32\u003e, scale: f32) -\u003e vec2\u003cf32\u003e {\n    let temp_p = p * mat;\n    let p_transformed = -1.0 + 2.0 * fract(sin(temp_p) * scale);\n    return sin(p_transformed * 6.283);\n}\n\nfn perlin_noise(p: vec2\u003cf32\u003e, mat: mat2x2\u003cf32\u003e, scale: f32) -\u003e f32 {\n    let pi = floor(p);\n    let pf = p - pi;\n    let w = pf * pf * (3.0 - 2.0 * pf);\n\n    let f00 = dot(hash22(pi + vec2\u003cf32\u003e(0.0, 0.0), mat, scale), pf - vec2\u003cf32\u003e(0.0, 0.0));\n    let f01 = dot(hash22(pi + vec2\u003cf32\u003e(0.0, 1.0), mat, scale), pf - vec2\u003cf32\u003e(0.0, 1.0));\n    let f10 = dot(hash22(pi + vec2\u003cf32\u003e(1.0, 0.0), mat, scale), pf - vec2\u003cf32\u003e(1.0, 0.0));\n    let f11 = dot(hash22(pi + vec2\u003cf32\u003e(1.0, 1.0), mat, scale), pf - vec2\u003cf32\u003e(1.0, 1.0));\n\n    let xm1 = mix(f00, f10, w.x);\n    let xm2 = mix(f01, f11, w.x);\n    let ym = mix(xm1, xm2, w.y);\n\n    return ym;\n}\n\nfn noise_sum(p: vec2\u003cf32\u003e, mat: mat2x2\u003cf32\u003e, scale: f32) -\u003e f32 {\n    var p_scaled = p * 4.0;\n    var a = 1.0;\n    var r = 0.0;\n    var s = 0.0;\n\n    for (var i = 0; i \u003c 5; i = i + 1) {\n        r = r + a * perlin_noise(p_scaled, mat, scale);\n        s = s + a;\n        p_scaled = p_scaled * 2.0;\n        a = a * 0.5;\n    }\n\n    return r / s;\n}\n```\n\nPerlin noise is a noise function designed to model randomness as seen in nature. Unlike simple random values, it uses gradient vectors at each point in space to create continuous and smooth noise patterns. This approach allows for more natural and consistent randomness.\n\nIn this code, two channels of Perlin noise are generated and stored in a single texture. These channels are used to create the terrain's height and color. By using different constants, the intention is to achieve a more diverse result.\n\nThe random function used here is not truly random but pseudorandom. By adding a uniform \"progress\" value based on the UV coordinates over time, it creates a more natural flow.\n\n## 2. Normal vector generation based on heightmap\n\n```js\nfn main(@builtin(global_invocation_id) id: vec3u) {\n    let x = f32(id.x);\n    let y = f32(id.y);\n\n    let size = f32(TEX_SIZE);\n\n    // Define neighboring coordinates with wrap-around logic\n    var left = vec2f((x - 1.0) / size, y / size);\n    var right = vec2f((x + 1.0) / size, y / size);\n    var down = vec2f(x / size, (y - 1.0) / size);\n    var up = vec2f(x / size, (y + 1.0) / size);\n\n    // Wrap around edges to handle boundary conditions\n    if (x == 0.0) {\n        left.x = (size - 1.0) / size;\n    }\n    if (x == size - 1.0) {\n        right.x = 0.0;\n    }\n    if (y == size - 1.0) {\n        up.y = 0.0;\n    }\n    if (y == 0.0) {\n        down.y = (size - 1.0) / size;\n    }\n\n    // Sample height values from the texture\n    let left_val:f32 = textureSampleLevel(noise_texture, my_sampler, left, 0).r;\n    let right_val:f32 = textureSampleLevel(noise_texture, my_sampler, right, 0).r;\n    let up_val:f32 = textureSampleLevel(noise_texture, my_sampler, up, 0).r;\n    let down_val:f32 = textureSampleLevel(noise_texture, my_sampler, down, 0).r;\n\n    // Compute gradient vectors\n    let dx = vec3f(2.0 / size, 0.0, (right_val - left_val) * uni.height_scale);\n    let dy = vec3f(0.0, 2.0 / size, (up_val - down_val) * uni.height_scale);\n\n    // Calculate normal vector using cross product\n    let normal = normalize(cross(dx, dy));\n\n    // Store the computed normal vector in the normal texture\n    textureStore(normal_texture, vec2\u003ci32\u003e(i32(x), i32(y)), vec4f(normal, 0.0));\n}\n\n// Cross product function for vec3f\nfn cross(a: vec3f, b: vec3f) -\u003e vec3f {\n    return vec3f(\n        a.y * b.z - a.z * b.y,\n        a.z * b.x - a.x * b.z,\n        a.x * b.y - a.y * b.x\n    );\n}\n```\n\nI calculated the normal vectors using height information from the heightmap. First, I computed the gradient vectors dx and dy through partial derivatives based on the neighboring grid information in the up, down, left, and right directions. Then, I calculated the normal vector by taking the cross product of these two gradient vectors and stored the result in a separate texture.\n\n## 3. Vertex shader: Sampling and Transforming Normals, Height, and Color from Textures\n\n```js\n@vertex fn vs(\n  input: Vertex,\n) -\u003e VSOutput {\n  var output: VSOutput;\n\n  let normal = textureSampleLevel(normal_map, my_sampler, input.tex_coord, 0);\n\n  let noise = textureSampleLevel(noise_map, my_sampler, input.tex_coord, 0);\n  let height = noise.r;\n  let color = noise.g;\n\n  var position = input.position;\n  position.z = scale_to_range(height, 0, uni.height_scale);\n\n  output.position = matrix_uni.projection * matrix_uni.view * matrix_uni.model * vec4f(position, 1.0);\n  output.pos_world = (matrix_uni.model * vec4f(position, 1.0)).xyz;\n  output.normal_world = normalize(matrix_uni.inv_transposed_model * normal).xyz;\n  output.height = height;\n  output.color = color;\n\n  return output;\n}\n```\n\nIn the vertex shader, I sample the normal vector and height from the normal_map and noise_map textures, respectively. The normal vector is transformed using the inverse transposed model matrix to obtain the world-space normal vector, which is then passed to the fragment shader. The height value is used to adjust the z coordinate of the vertex, thereby modifying the terrain's elevation. Additionally, the color extracted from the noise_map is passed along to the fragment shader for surface coloring.\n\n## 4. Fragment shader: Visual Effects\n\n```js\n@fragment fn fs(input: VSOutput) -\u003e @location(0) vec4f {\n    var albedo = mix(uni.color_1, uni.color_2, vec3f(input.color));\n\n    // snow\n    if(input.height \u003e uni.snow_height) {\n        albedo = vec3f(1.0);\n    }\n\n    let ambient_occlusion = pow(vec3f(input.height), vec3f(3.0));\n\n    var material:Material;\n    material.ambient = 0.1;\n    material.shininess = 1.0;\n    material.diffuse = 1.0;\n    material.specular = 1.0;\n\n    var light:Light;\n    light.direction = normalize(vec3f(-0.5, -0.5, -1.0));\n    light.strength = 3.0;\n\n    let cam_pos:vec3f = vec3f(0.0, 0.0, 2.5);\n    let to_eye:vec3f = normalize(cam_pos - input.pos_world);\n    let global_light = computeDirectionalLight(light, material, input.normal_world, to_eye);\n\n    let color = albedo * ambient_occlusion * global_light;\n\n    return vec4f(color, 1.0);\n}\n\n\nfn blinnPhong(material:Material, light_strength: vec3\u003cf32\u003e, light_vec: vec3\u003cf32\u003e, normal: vec3\u003cf32\u003e, to_eye: vec3\u003cf32\u003e) -\u003e vec3\u003cf32\u003e {\n    let halfway = normalize(to_eye + light_vec);\n    let hdotn = dot(halfway, normal);\n    let specular = material.specular * pow(max(hdotn, 0.0), material.shininess);\n    return material.ambient + (material.diffuse + specular) * light_strength;\n}\n\nfn computeDirectionalLight(light:Light, material:Material, normal: vec3\u003cf32\u003e, to_eye: vec3\u003cf32\u003e) -\u003e vec3\u003cf32\u003e {\n    let light_vec = -light.direction;\n    let ndotl = max(dot(light_vec, normal), 0.0);\n    let light_strength = vec3f(light.strength) * ndotl;\n\n    return blinnPhong(material, light_strength, light_vec, normal, to_eye);\n}\n```\n\nColor noise was used to blend two colors, creating a more natural texture. In the Vertex Shader, world-space normals were utilized to add shading with Blinn-Phong shading. Additionally, to account for the fact that lower heights in the terrain indicate valleys where light is less likely to reach, the height value was raised to a power and used for ambient occlusion.\n\n## Conclusion\n\nThrough this project, I learned how to generate terrain based on Perlin noise and render it visually appealingly using WebGPU. By utilizing normal vectors and ambient occlusion, I was able to realistically depict the terrain's depth and lighting effects. The powerful performance of WebGPU enabled high-resolution rendering.\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2e2a7597edf4d608.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"VLHl5AkiUdJz_Dj93meAW\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/post/terrain/\",\"initialTree\":[\"\",{\"children\":[\"post\",{\"children\":[[\"slug\",\"terrain\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"terrain\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialHead\":[false,\"$L5\"],\"globalErrorComponent\":\"$6\",\"children\":[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"mx-auto my-0\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"max-w-default mx-auto px-5 py-3\",\"children\":[\"$\",\"$L7\",null,{}]}],[\"$\",\"header\",null,{\"children\":[\"$\",\"$L8\",null,{}]}],[\"$\",\"div\",null,{\"className\":\"max-w-default mx-auto p-5\",\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"childProp\":{\"current\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"post\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"post\",\"children\",[\"slug\",\"terrain\",\"d\"],\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$Lb\",[\"$\",\"div\",null,{\"children\":[[\"$\",\"$Lc\",null,{\"href\":\"/posts/graphics\",\"className\":\"text-gray-600 text-md pl-1 hover:font-bold\",\"children\":\"GRAPHICS\"}],[\"$\",\"h1\",null,{\"children\":\"Terrain\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-400 text-sm m-0 mt-1\",\"children\":\"Sep 11, 2024\"}],[\"$\",\"div\",null,{\"className\":\"mt-1\",\"children\":[\"$\",\"div\",null,{\"className\":\"whitespace-nowrap overflow-x-auto pb-3\",\"children\":[[\"$\",\"$Lc\",\"simulation\",{\"href\":\"/tag/simulation\",\"className\":\"mr-2 text-gray-500 hover:font-bold\",\"children\":\"#simulation\"}],[\"$\",\"$Lc\",\"webgpu\",{\"href\":\"/tag/webgpu\",\"className\":\"mr-2 text-gray-500 hover:font-bold\",\"children\":\"#webgpu\"}],[\"$\",\"$Lc\",\"noise\",{\"href\":\"/tag/noise\",\"className\":\"mr-2 text-gray-500 hover:font-bold\",\"children\":\"#noise\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"mt-8\",\"children\":[\"$\",\"$Ld\",null,{\"content\":\"$e\"}]}],[\"$\",\"$Lf\",null,{\"issueTerm\":\"Terrain\"}]]}],null],\"segment\":\"__PAGE__?{\\\"slug\\\":\\\"terrain\\\"}\"},\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/602feae4669a507e.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}],null],\"segment\":[\"slug\",\"terrain\",\"d\"]},\"styles\":[]}],\"segment\":\"post\"},\"styles\":[]}]}],[\"$\",\"footer\",null,{\"className\":\"h-40 flex justify-center items-end\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-gray-500 text-sm\",\"children\":\"(C) 2021. Wayne Choi. All rights reserved.\"}]}]]}]}],null]}]]\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"WayneChoi.Dev\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Wayne Choi blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}]]\nb:null\n"])</script></body></html>